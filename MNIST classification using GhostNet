{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Modules import","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nimport torchvision\nfrom torchvision.transforms import v2\n\nfrom pathlib import Path\n\nimport pandas as pd\nimport time\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:38.822525Z","iopub.execute_input":"2024-11-18T04:52:38.823374Z","iopub.status.idle":"2024-11-18T04:52:44.035641Z","shell.execute_reply.started":"2024-11-18T04:52:38.823326Z","shell.execute_reply":"2024-11-18T04:52:44.034842Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, datapath, transform=None, train=True):\n        super().__init__()\n        _data = pd.read_csv(datapath)\n        self.transform = transform\n        self.init_transform = v2.Compose([\n            v2.ToImage(),\n            v2.ToDtype(torch.float64, scale=True)\n        ])\n        self.train = train\n        if train:\n            self.data = _data.iloc[:, 1:].to_numpy().astype('float64') / 255.\n            self.labels = _data.iloc[:, 0]\n        else:\n            self.data = _data.to_numpy().astype('float64') / 255.\n\n\n    def __getitem__(self, idx):\n        img = self.data[idx].reshape(28, 28)\n        img = self.init_transform(img)\n        if self.transform:\n            img = self.transform(img)\n        img = torch.cat([img] * 3, axis=0)\n        if self.train:\n            label = self.labels.iloc[idx]\n            label = F.one_hot(torch.tensor(label), num_classes=10)\n            return img, label\n        return img\n\n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:44.037196Z","iopub.execute_input":"2024-11-18T04:52:44.037629Z","iopub.status.idle":"2024-11-18T04:52:44.047244Z","shell.execute_reply.started":"2024-11-18T04:52:44.037594Z","shell.execute_reply":"2024-11-18T04:52:44.046194Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"transformations = {\"train\": v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float64, scale=True),\n    v2.RandomAffine(degrees=(-10, 10), translate=(0.2, 0.2)),\n    # v2.RandomHorizontalFlip(p=0.5),\n    # v2.RandomVerticalFlip(p=0.5),\n    v2.Resize(size=(224, 224)),\n    v2.Normalize(mean=[0.13], std=[0.31]),\n]), \"test\": v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float64, scale=True),\n    v2.Resize(size=(224, 224)),\n    v2.Normalize(mean=[0.13], std=[0.31]),\n])}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:44.048360Z","iopub.execute_input":"2024-11-18T04:52:44.048704Z","iopub.status.idle":"2024-11-18T04:52:44.057833Z","shell.execute_reply.started":"2024-11-18T04:52:44.048672Z","shell.execute_reply":"2024-11-18T04:52:44.056941Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"datapath = Path(\"/kaggle/input/digit-recognizer\")\nbatch_size = 32\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_dataset = MNISTDataset(datapath / \"train.csv\", transformations[\"train\"])\ntest_dataset = MNISTDataset(datapath / \"test.csv\", transformations[\"test\"], train=False)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:44.060740Z","iopub.execute_input":"2024-11-18T04:52:44.061430Z","iopub.status.idle":"2024-11-18T04:52:49.879365Z","shell.execute_reply.started":"2024-11-18T04:52:44.061396Z","shell.execute_reply":"2024-11-18T04:52:49.878529Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def train(model, dataloader, loss_fn, optimizer, scheduler, num_epochs, last_epochs=0):\n    size = len(dataloader.dataset)\n    \n    def train_epoch():\n        for batch, (X, y) in enumerate(dataloader):\n            X, y = X.to(device).float(), y.to(device).float()\n        \n            pred = model(X)\n            loss = loss_fn(pred, y)\n            \n            accuracy = (pred.argmax(dim=1) == y.argmax(dim=1)).sum().item() / y.size(0)\n    \n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n        \n            if batch % 100 == 0:\n                loss, current= loss.item(), (batch + 1) * len(X)\n                print(f\"loss: {loss:>7f}  accuracy: {accuracy:.3f}  [{current:>5d}/{size:>5d}]\")\n\n    \n    model.train()\n    for epoch in range(num_epochs - last_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        train_epoch()\n\n    if last_epochs:\n        for param in model.parameters():\n            param.requires_grad = True\n    \n    for epoch in range(last_epochs):\n        print(f'Epoch {num_epochs + epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        train_epoch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:49.880428Z","iopub.execute_input":"2024-11-18T04:52:49.880732Z","iopub.status.idle":"2024-11-18T04:52:49.890891Z","shell.execute_reply.started":"2024-11-18T04:52:49.880700Z","shell.execute_reply":"2024-11-18T04:52:49.889886Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def predict(model, dataloader):\n    model = model.to(device)\n    size = len(dataloader.dataset)\n    predictions = []\n    model.eval()\n    for batch, X in enumerate(dataloader):\n        X = X.to(device).float()\n        \n        pred = model(X).argmax(dim=1)\n        predictions.append(pred)\n        if batch % 100 == 0:\n            print(f\"[{batch}/{math.ceil(size / 32)}]\")\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:49.892011Z","iopub.execute_input":"2024-11-18T04:52:49.892300Z","iopub.status.idle":"2024-11-18T04:52:49.908066Z","shell.execute_reply.started":"2024-11-18T04:52:49.892268Z","shell.execute_reply":"2024-11-18T04:52:49.907172Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.classifier = nn.Linear(model.classifier.in_features, 10)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:49.908990Z","iopub.execute_input":"2024-11-18T04:52:49.909295Z","iopub.status.idle":"2024-11-18T04:52:58.534698Z","shell.execute_reply.started":"2024-11-18T04:52:49.909264Z","shell.execute_reply":"2024-11-18T04:52:58.533806Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/huawei-noah/ghostnet/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/huawei-noah/ghostnet/raw/master/ghostnet_pytorch/models/state_dict_73.98.pth\" to /root/.cache/torch/hub/checkpoints/state_dict_73.98.pth\n100%|██████████| 20.0M/20.0M [00:00<00:00, 171MB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"epochs = 10\nlr = 1e-3\nsteps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=epochs, steps_per_epoch=steps_per_epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:58.536256Z","iopub.execute_input":"2024-11-18T04:52:58.536829Z","iopub.status.idle":"2024-11-18T04:52:58.544569Z","shell.execute_reply.started":"2024-11-18T04:52:58.536784Z","shell.execute_reply":"2024-11-18T04:52:58.543435Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train(model, train_dataloader, loss_fn, optimizer, scheduler, epochs, last_epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T04:52:58.545973Z","iopub.execute_input":"2024-11-18T04:52:58.546664Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\nloss: 2.312366  accuracy: 0.062  [   32/42000]\nloss: 2.195899  accuracy: 0.281  [ 3232/42000]\nloss: 2.163424  accuracy: 0.188  [ 6432/42000]\nloss: 2.085053  accuracy: 0.188  [ 9632/42000]\nloss: 1.935056  accuracy: 0.562  [12832/42000]\nloss: 1.823773  accuracy: 0.594  [16032/42000]\nloss: 1.679750  accuracy: 0.562  [19232/42000]\nloss: 1.650327  accuracy: 0.594  [22432/42000]\nloss: 1.558037  accuracy: 0.719  [25632/42000]\nloss: 1.227157  accuracy: 0.844  [28832/42000]\nloss: 1.390543  accuracy: 0.656  [32032/42000]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"preds = predict(model, test_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from functools import reduce, partial\nimport numpy as np\n\nconcat = partial(np.concatenate, axis=0)\nmmm = [x.cpu().numpy() for x in preds]\npredictions = reduce(lambda x, y: concat((x, y)), mmm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = {\"ImageId\": np.arange(1, len(predictions) + 1),\n             \"Label\": predictions}\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission.set_index(\"ImageId\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}